---
date: "10-8-22"
title: "Emotion Detection from Facial Micro-experessions"
builder: "ครองภพ มั่นคง (ไบรท์)"
builder_info: ""
thumbnail: "/images/2022/61/01.jpg"
links:
    github: "https://github.com/Doraminn/Micro-expression/"
    facebook: "https://facebook.com/aibuildersx/posts/449331850568593"
    blog: "https://medium.com/@brightkorn132/%E0%B9%80%E0%B8%88%E0%B9%87%E0%B8%9A%E0%B9%81%E0%B8%84%E0%B9%88%E0%B9%84%E0%B8%AB%E0%B8%99%E0%B8%81%E0%B9%87%E0%B8%95%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%9D%E0%B8%B7%E0%B8%99%E0%B8%A2%E0%B8%B4%E0%B9%89%E0%B8%A1%E0%B8%A7%E0%B9%88%E0%B8%B2%E0%B9%84%E0%B8%A1%E0%B9%88%E0%B9%80%E0%B8%9B%E0%B9%87%E0%B8%99%E0%B9%84%E0%B8%A3-42c31e7cfdc1"
---

![image](/images/2022/61/01.jpg)

- โมเดลตรวจจับอารมณ์เสี้ยววิหรือ Micro-expressions (Anger, Contempt, Happniess, Others, Surprise) จากรูปหน้า,
- Micro-expression เป็นการแสดงอารมณ์ที่รู้สึกจริง ๆ แต่ต้องโกหกเอาไว้ และเกิดขึ้นเร็วมากจนมนุษย์ทั่วไปไม่สามารถรับรู้ได้เลย ถ้าสมมติมีโมเดลที่สามารถตรวจและระบุอารมณ์นี้ได้อย่างแม่นยำ ก็จะสามารถจับอารมณ์ที่โกหกอยู่ได้และมีประโยชน์เป็นอย่างมากเช่นการจับโกหกในการนำไปเป็นพยานหลักฐานของสืบสวนคดีต่าง ๆ,
- ใช้ชุดข้อมูล SAMM dataset ประกอบไปด้วยรูปภาพที่แคปมาจากวิดีโอที่ถ่ายด้วยกล้องความเร็ว 200 fps มีทั้งหมด 29 subjects 159 samples แต่ละ sample มีรูปประมาณ 30-100 รูป,
- ดูตัวอย่าง micro expression ได้ที่ https://www.facebook.com/aibuildersx/videos/1455685481578809,
- ชุดข้อมูลมี 7 อารมณ์ ได้แก่ Happiness, Sadness, Anger, Disgust, Contempt, Fear และ Other แต่ Sadness, Fear และ Disgust มีจำนวนรูปน้อยเกินไปจึงตัดออกเพื่อป้องกัน label imbalance,
- แต่ละเฟรมของชุดข้อมูลถูกจดไว้ว่าเป็น Onset frame (หมายเลขเฟรมที่เริ่มอัดคลิป), Apex frame (หมายเลขเฟรมที่เป็นจุดพีคของการเกิด micro-expression), Offset frame (หมายเลขเฟรมที่จบการอัดคลิป) และ Duration (จำนวนเฟรมที่จับได้ ซึ่งสอดคล้องกับจำนวนรูปในไฟล์),
- จัดการแปลงรูปเพื่อเข้าสู่โมเดล 4 รูปแบบคือ 1) Original Apex frame — ใช้เฟรม ณ จุด Apex มาเป็น input 2) Difference of Apex frame and Onset frame — เนื่องด้วยเราได้แปลงข้อมูลภาพของเราเป็นตัวเลขเมื่อนำเข้าโมเดล จึงลองเอาผลต่างของ Apex กับ Onset มาเป็น input เพื่อแสดงว่าภาพตอนพีคกับตอนเริ่มต่างกันยังไง 3) Optical flow of Apex frame and Onset frame — เปลี่ยนจากผลต่างตัวเลขของ 2 เฟรมมาเป็น Optical flow ซึ่งก็คือแพทเทิร์นการขยับของภาพ โดยจะแสดงเป็นกลุ่มการไหลของแสง 4) Optical flow of Apex frame and Onset frame + Original Apex frame — คือการนำทั้ง Optical flow เมื่อกี้และภาพของ input แบบที่ 1 มารวมกันและนำไปเป็น input,
- เลือกใช้ ResNet-18 ที่ pretrained มาจาก EfficientFace ซึ่งเทรนมาจาก MS-Celeb-1M และมีจำนวน class มากถึง 12,666 คน,
- สร้างแบบทดสอบ 10 หน้าจากรูปที่ไม่ได้ใช้เทรนโมเดล โมเดลตอบถูก 6 จาก 10 ข้อเทียบกับมนุษย์ 29 คนที่ตอบถูก 2.759 ข้อโดยเฉลี่ย,
- ปัญหาที่พบและน่าทำการแก้ไขในอนาคต 1) จำนวนข้อมูลที่มีน้อย 2) ความ Imbalance ของข้อมูลในแต่ละ class 3) sample บางคลิป แทบไม่ขยับหรือขยับน้อยมาก 4) sample บางคลิป มีตำแหน่งหน้า ที่ไม่ตรงกันใน Apex frame กับ Onset frame ทำให้ optical flow ฟุ้งกระจาย

### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)

> "เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง"