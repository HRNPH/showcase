---
date: "8-8-22"
title: "GANime-FullBody วาดรูปตัวละครอนิเมะ(สาวๆ)แบบเต็มตัว ด้วย Deep Learning"
builder: "หิรัญกุล พิมพ์ศิริ (ไกด์)"
builder_info: ""
thumbnail: "/images/2022/59/01.jpg"
links:
    github: "https://hrnph.github.io/GANime-FullBody/"
    facebook: "https://facebook.com/aibuildersx/posts/445888770912901"
    blog: "https://medium.com/@hrnph/%E0%B8%A7%E0%B8%B2%E0%B8%94%E0%B8%A3%E0%B8%B9%E0%B8%9B%E0%B8%95%E0%B8%B1%E0%B8%A7%E0%B8%A5%E0%B8%B0%E0%B8%84%E0%B8%A3%E0%B8%AD%E0%B8%99%E0%B8%B4%E0%B9%80%E0%B8%A1%E0%B8%B0%E0%B8%AA%E0%B8%B2%E0%B8%A7%E0%B9%86-%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B9%80%E0%B8%95%E0%B9%87%E0%B8%A1%E0%B8%95%E0%B8%B1%E0%B8%A7-%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-deep-learning-ganime-fullbody-9b3822e58934"
---

![image](/images/2022/59/01.jpg)

- โมเดล Generative Adversarial Network (GAN) สำหรับสร้างรูปวาดตัวละครสาวน้อยอนิเมะ; แรงบันดาลใจจากความชื่นชอบในอนิเมะและประสบการณ์ในการทำเกมที่จำเป็นต้องออกแบบตัวละครใหม่เรื่อยๆ จึงคิดว่าน่าจะสะดวกขึ้นหากมีโมเดลที่สร้างสาวน้อยอนิเมะออกมาให้เลือกปรับใช้กับทั้งเกม, ไลท์โนเวล, รูปประกอบ ฯลฯ,
- เลือกใช้ GAN มากกว่า Variational Autoencoder (VAE) เนื่องจากได้ภาพที่คมชัดกว่า; ด้วยข้อจำกัดทางเวลาและทรัพยากร ตั้งเป้าสร้างรูปขนาด 32², 64² หรือ 128² pixels,
- สร้างชุดข้อมูลขึ้นมาเองด้วยมาตรฐานว่ารูปต้อง 1) ไม่มีพื้นหลัง (ขาวล้วน) 2) ลายเส้นและลักษณะตรงความต้องการ (เต็มตัว, ลายเส้นญี่ปุ่น, ตัวละครหญิง) 3) ชุดข้อมูลที่มีขนาดใหญ่ เนื่องจาก GAN ต้องใช้ชุดข้อมูลจำนวนมาก (10k ++),
- เปรียบเทียบแหล่งข้อมูลที่จะรวบรวมมาเพื่อสร้างชุดข้อมูลหลายแห่ง เช่น Getchu ที่ปริมาณและคุณภาพดีที่สุดแต่การเชื่อมต่อไม่เสถียรพอ, Gelbooru ที่ปริมาณและคุณภาพดีเช่นกันแต่เต็มไปด้วยรูป 18+ จึงลงท้ายที่ Safebooru ซึ่งเป็น Gelbooru เวอร์ชั่นที่คัดรูป 18+ ออกแล้วโดยใช้แท้ก full_body solo, standing, 1girl, white_background เพื่อให้ได้รูปสาวน้อยอนิเมะเต็มตัวพื้นหลังสีขาว,
- ทำความสะอาดข้อมูลด้วยการคัดรูปต่อไปนี้ออก 1) ตัวละครจิบิ (หัวโตตัวเล็ก) 2) ภาพที่มีมากกว่า 1 ตัวละคร 3) พื้นหลังสีฉูดฉาด/ท่ายืนแปลกๆ; โดยตัวละครจิบิเป็นรูปประเภทที่ไม่ต้องการที่เยอะที่สุด,
- ทำโมเดลคัดแยกรูปที่ไม่ต้องการด้วย ResNet34 2 โมเดลคือ Chibi(~1k datasets) และ More Than 1(~0.3k datasets) ได้ผลอย่างดีเยี่ยม F1 0.96-0.98; เหลือชุดข้อมูลหลังทำความสะอาดแล้ว 12k รูป,
- ขั้นตอนการเทรนเริ่มจากใช้ DCGAN พบว่า generator (โมเดลสร้างภาพปลอม) แทบไม่ได้เรียนรู้เลยเพราะ discriminator (โมเดลจับว่าภาพจริงหรือปลอม) เรียนรู้เร็วจนเกินไป คาดว่าปัญหาเกิดจาก vanishing gradients ของ BCE Loss ที่ใช้กับ discriminator จึงเปลี่ยนมาใช้ Wasserstein Loss และเพิ่ม gradient penalty เพื่อไม่ให้ loss ลดลงใกล้ 0 เร็วจนเกินไป,
- จากนั้นปรับปรุงสถาปัตยกรรมโดยเปลี่ยนจาก DCGAN มาใช้ Progressive GAN ที่จะค่อยๆจับ Feature ที่ความละเอียดต่ำๆก่อน ในภาพ 4² เมื่อคุ้นชินแล้วก็จะเริ่มปรัปความละเอียดในสูงขึ้น เป็น 8² แล้วค่อยๆเพิ่มไปเรื่อยๆ จนถึง Scaling เป้าหมาย ที่ 128²,
- เพิ่มประสิทธิผลของ generator อีกขั้นโดยการปรับใช้เทคนิคจาก StyleGAN คือ 1) Mapping Network จัดเรียง Random Noise ให้มีรูปแบบ 2) Adaptive Instance Normalization (AdaIN) เพื่อทำ style transfer; StyleGAN ได้ผลดีพอๆกับ Progressive GAN โดยใช้เวลาที่สั้นกว่า; เทรนโมเดลด้วยสถาปัตยกรรมและชุดข้อมูลนี้ เรียกว่า Model A,
- เมื่อสถาปัตยกรรมเป็นที่พอใจแล้วกลับไปทำความสะอาดข้อมูลอีกรอบ เนื่องจากพบว่ารูปที่มี effect หรือชุดอลังการงานสร้างเกินไปจะทำให้โมเดลเรียนรู้ได้ยาก; ใช้ ResNet50 ในการคัดแยกรูปที่ต้องการและไม่ต้องการ โดยเทรนจากข้อมูลกำกับเองด้วยมือ 500 รูป, ได้ผลไม่ดีนัก (precision 0.4) ทำให้ข้อมูลถูกทำความสะอาดไปเหลือเพียงประมาณ 5 พันรูป,
- ลองเทรน Model B บนข้อมูล 5 พันรูปนั้นแล้วพบว่าความสวยงามเป็นที่น่าพึงพอใจแม้ปริมาณรูปจะลดลงเกินครึ่ง,
- ใช้ Fréchet inception distance (FID; ยิ่งน้อยยิ่งดี) ในการวัดผลเทียบรูปที่สร้างจาก Model A กับ Model B อย่างละ 1 หมื่นรูปกับรูปจริง พบว่า Model B ทำได้ดีกว่าเกือบเท่าตัว (data-centric มั้ยละคุณ!),
- แม้จะมีผลลัพท์ที่ออกมาน่ากลัวอยู่บ้าง แต่โดยรวมแล้วผลลัพท์ที่ออกมา ถือว่าน่าพึงพอใจ โมเดลสามารถจับดีเทลขาได้อย่างสวยงาม ชุดที่ถูกลักษณะ ร่างกายที่สมส่วน และยังพยายามเติมหน้าเข้าไปในทุกๆโมเดล; สิ่งที่จะพัฒนาต่อหลังจากนี้คือ 1) การทดลองปรัป Noise ของโมเดล และทดสอบ Latent W เพื่อหา Style แต่ละส่วน 2) การทำให้ภาพชัดขึ้นที่ 256² 3) การหา Datasets ที่ดีขึ้นเพื่อเพิ่มคุณภาพของโมเดล 4) การ Deploy ที่ผู้ใช้สามารถปรัป Style ของรูปได้,
- เปิดชุดข้อมูลลิขสิทธิ์การรวบรวมเป็น open source ที่: https://www.kaggle.com/datasets/hirunkulphimsiri/fullbody-anime-girls-datasets,
- เปิด Docker Image สำหรับ deploy API เป็น open source ที่: https://gallery.ecr.aws/z1f5v2y8/ganime-fullbody/model0

### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)

> "เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง"